{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "692cfe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca.to_csv(r'I:\\\\verisetleri1\\\\IoTID20\\\\X_train.csv')\n",
    "X_test_pca.to_csv(r'I:\\\\verisetleri1\\\\IoTID20\\\\X_test.csv')\n",
    "Y_test.to_csv(r'I:\\\\verisetleri1\\\\IoTID20\\\\y_test.csv')\n",
    "y_train_pca.to_csv(r'I:\\\\verisetleri1\\\\IoTID20\\\\y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b728c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "start = time.time()\n",
    "#read data in chunks of 1 million rows at a time\n",
    "chunk1 = pd.read_csv('I:\\\\verisetleri1\\\\IoTID20\\\\X_train.csv',chunksize=1000000)\n",
    "chunk2 = pd.read_csv('I:\\\\verisetleri1\\\\IoTID20\\\\X_test.csv',chunksize=1000000)\n",
    "chunk3 = pd.read_csv('I:\\\\verisetleri1\\\\IoTID20\\\\y_test.csv',chunksize=1000000)\n",
    "chunk4 = pd.read_csv('I:\\\\verisetleri1\\\\IoTID20\\\\y_test.csv',chunksize=1000000)\n",
    "\n",
    "\n",
    "x_train = pd.concat(chunk1)\n",
    "x_test  = pd.concat(chunk2)\n",
    "y_train = pd.concat(chunk3)\n",
    "y_test  = pd.concat(chunk4)\n",
    "\n",
    "X_train= x_train.drop(['Unnamed: 0'], axis=1)\n",
    "X_test= x_test.drop(['Unnamed: 0'], axis=1)\n",
    "Y_train= y_train.drop(['Unnamed: 0'], axis=1)\n",
    "Y_test= y_test.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c57009d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c3e2601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_train1 = to_categorical(Y_train, num_classes=2)\n",
    "y_test1 = to_categorical(Y_test, num_classes=2)\n",
    "### reshape input data to LSTM format [samples, time_steps, features]\n",
    "X_train_lstm = X_resample.reshape(X_resample.shape[0], 1, X_resample.shape[1])\n",
    "X_test_lstm = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "print(f\"shape of X_train:\", X_train_lstm.shape)\n",
    "print(f\"shape of X_test:\", X_test_lstm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f8ad808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "import keras\n",
    "from keras.layers.convolutional import Conv1D \n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6024b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07caf7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4880bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f82cd54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae237ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "def model1():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=6, activation='relu', \n",
    "                    padding='same', input_shape=(77, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # adding a pooling layer\n",
    "    model.add(MaxPooling1D(pool_size=(2), strides=2, padding='same'))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=6, activation='relu', \n",
    "                    padding='same', input_shape=(77, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=(2), strides=2, padding='same'))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=6, activation='relu', \n",
    "                    padding='same', input_shape=(77, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=(2), strides=2, padding='same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model and add precision and recall metrics\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy', Precision(), Recall()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b2a2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "batch_size = 1024\n",
    "no_epochs = 200\n",
    "verbosity = 1\n",
    "n_classes = 2\n",
    "loss_function = \"sparse_categorical_crossentropy\"\n",
    "optimizer = 'Adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85220f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "343/343 [==============================] - 121s 339ms/step - loss: 0.0449 - accuracy: 0.9869 - precision: 0.9869 - recall: 0.9869 - val_loss: 0.0802 - val_accuracy: 0.9772 - val_precision: 0.9772 - val_recall: 0.9772\n",
      "Epoch 2/200\n",
      "343/343 [==============================] - 119s 346ms/step - loss: 0.0235 - accuracy: 0.9947 - precision: 0.9947 - recall: 0.9947 - val_loss: 0.0239 - val_accuracy: 0.9940 - val_precision: 0.9940 - val_recall: 0.9940\n",
      "Epoch 3/200\n",
      "343/343 [==============================] - 117s 342ms/step - loss: 0.0192 - accuracy: 0.9958 - precision: 0.9958 - recall: 0.9958 - val_loss: 0.0174 - val_accuracy: 0.9963 - val_precision: 0.9963 - val_recall: 0.9963\n",
      "Epoch 4/200\n",
      "343/343 [==============================] - 110s 320ms/step - loss: 0.0179 - accuracy: 0.9960 - precision: 0.9960 - recall: 0.9960 - val_loss: 0.0188 - val_accuracy: 0.9957 - val_precision: 0.9957 - val_recall: 0.9957\n",
      "Epoch 5/200\n",
      "343/343 [==============================] - 111s 325ms/step - loss: 0.0172 - accuracy: 0.9962 - precision: 0.9962 - recall: 0.9962 - val_loss: 0.0185 - val_accuracy: 0.9955 - val_precision: 0.9955 - val_recall: 0.9955\n",
      "Epoch 6/200\n",
      "343/343 [==============================] - 111s 324ms/step - loss: 0.0176 - accuracy: 0.9961 - precision: 0.9961 - recall: 0.9961 - val_loss: 0.0251 - val_accuracy: 0.9931 - val_precision: 0.9931 - val_recall: 0.9931\n",
      "Epoch 7/200\n",
      "343/343 [==============================] - 112s 326ms/step - loss: 0.0163 - accuracy: 0.9965 - precision: 0.9965 - recall: 0.9965 - val_loss: 0.0399 - val_accuracy: 0.9919 - val_precision: 0.9919 - val_recall: 0.9919\n",
      "Epoch 8/200\n",
      "343/343 [==============================] - 111s 324ms/step - loss: 0.0155 - accuracy: 0.9967 - precision: 0.9967 - recall: 0.9967 - val_loss: 0.0204 - val_accuracy: 0.9967 - val_precision: 0.9967 - val_recall: 0.9967\n",
      "Epoch 9/200\n",
      "343/343 [==============================] - 112s 325ms/step - loss: 0.0153 - accuracy: 0.9968 - precision: 0.9968 - recall: 0.9968 - val_loss: 0.0162 - val_accuracy: 0.9967 - val_precision: 0.9967 - val_recall: 0.9967\n",
      "Epoch 10/200\n",
      "343/343 [==============================] - 111s 324ms/step - loss: 0.0160 - accuracy: 0.9966 - precision: 0.9966 - recall: 0.9966 - val_loss: 0.0155 - val_accuracy: 0.9967 - val_precision: 0.9967 - val_recall: 0.9967\n",
      "Epoch 11/200\n",
      "343/343 [==============================] - 111s 323ms/step - loss: 0.0146 - accuracy: 0.9970 - precision: 0.9970 - recall: 0.9970 - val_loss: 0.0153 - val_accuracy: 0.9969 - val_precision: 0.9969 - val_recall: 0.9969\n",
      "Epoch 12/200\n",
      "343/343 [==============================] - 110s 321ms/step - loss: 0.0145 - accuracy: 0.9970 - precision: 0.9970 - recall: 0.9970 - val_loss: 0.0163 - val_accuracy: 0.9966 - val_precision: 0.9966 - val_recall: 0.9966\n",
      "Epoch 13/200\n",
      "343/343 [==============================] - 111s 324ms/step - loss: 0.0145 - accuracy: 0.9969 - precision: 0.9969 - recall: 0.9969 - val_loss: 0.0155 - val_accuracy: 0.9968 - val_precision: 0.9968 - val_recall: 0.9968\n",
      "Epoch 14/200\n",
      "343/343 [==============================] - 111s 323ms/step - loss: 0.0166 - accuracy: 0.9964 - precision: 0.9964 - recall: 0.9964 - val_loss: 0.0278 - val_accuracy: 0.9912 - val_precision: 0.9912 - val_recall: 0.9912\n",
      "Epoch 15/200\n",
      "343/343 [==============================] - 112s 326ms/step - loss: 0.0162 - accuracy: 0.9966 - precision: 0.9966 - recall: 0.9966 - val_loss: 0.0160 - val_accuracy: 0.9967 - val_precision: 0.9967 - val_recall: 0.9967\n",
      "Epoch 16/200\n",
      "343/343 [==============================] - 103s 300ms/step - loss: 0.0147 - accuracy: 0.9970 - precision: 0.9970 - recall: 0.9970 - val_loss: 0.0159 - val_accuracy: 0.9967 - val_precision: 0.9967 - val_recall: 0.9967\n",
      "Epoch 17/200\n",
      "343/343 [==============================] - 94s 275ms/step - loss: 0.0138 - accuracy: 0.9971 - precision: 0.9971 - recall: 0.9971 - val_loss: 0.0167 - val_accuracy: 0.9959 - val_precision: 0.9959 - val_recall: 0.9959\n",
      "Epoch 18/200\n",
      "343/343 [==============================] - 102s 297ms/step - loss: 0.0137 - accuracy: 0.9972 - precision: 0.9972 - recall: 0.9972 - val_loss: 0.0154 - val_accuracy: 0.9968 - val_precision: 0.9968 - val_recall: 0.9968\n",
      "Epoch 19/200\n",
      "343/343 [==============================] - 97s 284ms/step - loss: 0.0137 - accuracy: 0.9972 - precision: 0.9972 - recall: 0.9972 - val_loss: 0.1171 - val_accuracy: 0.9880 - val_precision: 0.9880 - val_recall: 0.9880\n",
      "Epoch 20/200\n",
      "343/343 [==============================] - 99s 288ms/step - loss: 0.0199 - accuracy: 0.9954 - precision: 0.9954 - recall: 0.9954 - val_loss: 0.0164 - val_accuracy: 0.9967 - val_precision: 0.9967 - val_recall: 0.9967\n",
      "Epoch 21/200\n",
      "343/343 [==============================] - 97s 282ms/step - loss: 0.0142 - accuracy: 0.9971 - precision: 0.9971 - recall: 0.9971 - val_loss: 0.0155 - val_accuracy: 0.9969 - val_precision: 0.9969 - val_recall: 0.9969\n",
      "Epoch 22/200\n",
      "343/343 [==============================] - 100s 292ms/step - loss: 0.0138 - accuracy: 0.9971 - precision: 0.9971 - recall: 0.9971 - val_loss: 0.0152 - val_accuracy: 0.9971 - val_precision: 0.9971 - val_recall: 0.9971\n",
      "Epoch 23/200\n",
      "343/343 [==============================] - 97s 283ms/step - loss: 0.0135 - accuracy: 0.9972 - precision: 0.9972 - recall: 0.9972 - val_loss: 0.0146 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 24/200\n",
      "343/343 [==============================] - 95s 277ms/step - loss: 0.0133 - accuracy: 0.9972 - precision: 0.9972 - recall: 0.9972 - val_loss: 0.0149 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 25/200\n",
      "343/343 [==============================] - 97s 282ms/step - loss: 0.0131 - accuracy: 0.9973 - precision: 0.9973 - recall: 0.9973 - val_loss: 0.0149 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 26/200\n",
      "343/343 [==============================] - 95s 276ms/step - loss: 0.0130 - accuracy: 0.9973 - precision: 0.9973 - recall: 0.9973 - val_loss: 0.0154 - val_accuracy: 0.9969 - val_precision: 0.9969 - val_recall: 0.9969\n",
      "Epoch 27/200\n",
      "343/343 [==============================] - 96s 280ms/step - loss: 0.0132 - accuracy: 0.9972 - precision: 0.9972 - recall: 0.9972 - val_loss: 0.0148 - val_accuracy: 0.9969 - val_precision: 0.9969 - val_recall: 0.9969\n",
      "Epoch 28/200\n",
      "343/343 [==============================] - 100s 290ms/step - loss: 0.0142 - accuracy: 0.9970 - precision: 0.9970 - recall: 0.9970 - val_loss: 0.0150 - val_accuracy: 0.9969 - val_precision: 0.9969 - val_recall: 0.9969\n",
      "Epoch 29/200\n",
      "343/343 [==============================] - 97s 282ms/step - loss: 0.0129 - accuracy: 0.9973 - precision: 0.9973 - recall: 0.9973 - val_loss: 0.0150 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 30/200\n",
      "343/343 [==============================] - 97s 282ms/step - loss: 0.0128 - accuracy: 0.9973 - precision: 0.9973 - recall: 0.9973 - val_loss: 0.0150 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 31/200\n",
      "343/343 [==============================] - 92s 269ms/step - loss: 0.0128 - accuracy: 0.9973 - precision: 0.9973 - recall: 0.9973 - val_loss: 0.0147 - val_accuracy: 0.9969 - val_precision: 0.9969 - val_recall: 0.9969\n",
      "Epoch 32/200\n",
      "343/343 [==============================] - 92s 270ms/step - loss: 0.0127 - accuracy: 0.9973 - precision: 0.9973 - recall: 0.9973 - val_loss: 0.0146 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 33/200\n",
      "343/343 [==============================] - 93s 270ms/step - loss: 0.0129 - accuracy: 0.9973 - precision: 0.9973 - recall: 0.9973 - val_loss: 0.0146 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 34/200\n",
      "343/343 [==============================] - 93s 272ms/step - loss: 0.0125 - accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.0146 - val_accuracy: 0.9972 - val_precision: 0.9972 - val_recall: 0.9972\n",
      "Epoch 35/200\n",
      "343/343 [==============================] - 93s 270ms/step - loss: 0.0124 - accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.0153 - val_accuracy: 0.9969 - val_precision: 0.9969 - val_recall: 0.9969\n",
      "Epoch 36/200\n",
      "343/343 [==============================] - 93s 270ms/step - loss: 0.0124 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - val_loss: 0.0150 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 37/200\n",
      "343/343 [==============================] - 93s 270ms/step - loss: 0.0151 - accuracy: 0.9966 - precision: 0.9966 - recall: 0.9966 - val_loss: 0.0149 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 38/200\n",
      "343/343 [==============================] - 96s 279ms/step - loss: 0.0125 - accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.0146 - val_accuracy: 0.9968 - val_precision: 0.9968 - val_recall: 0.9968\n",
      "Epoch 39/200\n",
      "343/343 [==============================] - 97s 282ms/step - loss: 0.0124 - accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.0151 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 40/200\n",
      "343/343 [==============================] - 95s 278ms/step - loss: 0.0123 - accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.0151 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 41/200\n",
      "343/343 [==============================] - 92s 269ms/step - loss: 0.0124 - accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.0142 - val_accuracy: 0.9971 - val_precision: 0.9971 - val_recall: 0.9971\n",
      "Epoch 42/200\n",
      "343/343 [==============================] - 92s 268ms/step - loss: 0.0120 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - val_loss: 0.0148 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 43/200\n",
      "343/343 [==============================] - 92s 270ms/step - loss: 0.0139 - accuracy: 0.9972 - precision: 0.9972 - recall: 0.9972 - val_loss: 0.0142 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 44/200\n",
      "343/343 [==============================] - 92s 269ms/step - loss: 0.0121 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - val_loss: 0.0141 - val_accuracy: 0.9972 - val_precision: 0.9972 - val_recall: 0.9972\n",
      "Epoch 45/200\n",
      "343/343 [==============================] - 92s 268ms/step - loss: 0.0117 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - val_loss: 0.0146 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 46/200\n",
      "343/343 [==============================] - 92s 268ms/step - loss: 0.0117 - accuracy: 0.9976 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.0139 - val_accuracy: 0.9971 - val_precision: 0.9971 - val_recall: 0.9971\n",
      "Epoch 47/200\n",
      "343/343 [==============================] - 92s 268ms/step - loss: 0.0118 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - val_loss: 0.0149 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 48/200\n",
      "343/343 [==============================] - 93s 272ms/step - loss: 0.0120 - accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.0153 - val_accuracy: 0.9968 - val_precision: 0.9968 - val_recall: 0.9968\n",
      "Epoch 49/200\n",
      "343/343 [==============================] - 92s 269ms/step - loss: 0.0116 - accuracy: 0.9976 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.0140 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 50/200\n",
      "343/343 [==============================] - 92s 268ms/step - loss: 0.0116 - accuracy: 0.9976 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.0150 - val_accuracy: 0.9968 - val_precision: 0.9968 - val_recall: 0.9968\n",
      "Epoch 51/200\n",
      "343/343 [==============================] - 92s 268ms/step - loss: 0.0116 - accuracy: 0.9976 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.0141 - val_accuracy: 0.9972 - val_precision: 0.9972 - val_recall: 0.9972\n",
      "Epoch 52/200\n",
      "343/343 [==============================] - 97s 282ms/step - loss: 0.0116 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - val_loss: 0.0144 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 53/200\n",
      "343/343 [==============================] - 107s 312ms/step - loss: 0.0114 - accuracy: 0.9976 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.0141 - val_accuracy: 0.9972 - val_precision: 0.9972 - val_recall: 0.9972\n",
      "Epoch 54/200\n",
      "343/343 [==============================] - 101s 294ms/step - loss: 0.0115 - accuracy: 0.9976 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.0150 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 55/200\n",
      "343/343 [==============================] - 104s 302ms/step - loss: 0.0116 - accuracy: 0.9976 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.0151 - val_accuracy: 0.9969 - val_precision: 0.9969 - val_recall: 0.9969\n",
      "Epoch 56/200\n",
      "343/343 [==============================] - 96s 281ms/step - loss: 0.0117 - accuracy: 0.9976 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.0146 - val_accuracy: 0.9971 - val_precision: 0.9971 - val_recall: 0.9971\n",
      "Epoch 57/200\n",
      "343/343 [==============================] - 97s 283ms/step - loss: 0.0116 - accuracy: 0.9976 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.0139 - val_accuracy: 0.9973 - val_precision: 0.9973 - val_recall: 0.9973\n",
      "Epoch 58/200\n",
      "343/343 [==============================] - 101s 296ms/step - loss: 0.0114 - accuracy: 0.9977 - precision: 0.9977 - recall: 0.9977 - val_loss: 0.0141 - val_accuracy: 0.9973 - val_precision: 0.9973 - val_recall: 0.9973\n",
      "Epoch 59/200\n",
      "343/343 [==============================] - 96s 279ms/step - loss: 0.0114 - accuracy: 0.9976 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.0146 - val_accuracy: 0.9971 - val_precision: 0.9971 - val_recall: 0.9971\n",
      "Epoch 60/200\n",
      "343/343 [==============================] - 96s 280ms/step - loss: 0.0136 - accuracy: 0.9970 - precision: 0.9970 - recall: 0.9970 - val_loss: 0.0142 - val_accuracy: 0.9971 - val_precision: 0.9971 - val_recall: 0.9971\n",
      "Epoch 61/200\n",
      "343/343 [==============================] - 92s 269ms/step - loss: 0.0116 - accuracy: 0.9976 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.0152 - val_accuracy: 0.9969 - val_precision: 0.9969 - val_recall: 0.9969\n",
      "Epoch 62/200\n",
      "343/343 [==============================] - 92s 269ms/step - loss: 0.0114 - accuracy: 0.9976 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.0144 - val_accuracy: 0.9971 - val_precision: 0.9971 - val_recall: 0.9971\n",
      "Epoch 63/200\n",
      "343/343 [==============================] - 97s 281ms/step - loss: 0.0113 - accuracy: 0.9976 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.0141 - val_accuracy: 0.9971 - val_precision: 0.9971 - val_recall: 0.9971\n",
      "Epoch 64/200\n",
      "343/343 [==============================] - 96s 279ms/step - loss: 0.0112 - accuracy: 0.9977 - precision: 0.9977 - recall: 0.9977 - val_loss: 0.0140 - val_accuracy: 0.9972 - val_precision: 0.9972 - val_recall: 0.9972\n",
      "Epoch 65/200\n",
      "343/343 [==============================] - 96s 278ms/step - loss: 0.0110 - accuracy: 0.9977 - precision: 0.9977 - recall: 0.9977 - val_loss: 0.0143 - val_accuracy: 0.9971 - val_precision: 0.9971 - val_recall: 0.9971\n",
      "Epoch 66/200\n",
      "343/343 [==============================] - 92s 269ms/step - loss: 0.0112 - accuracy: 0.9976 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.0176 - val_accuracy: 0.9960 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 67/200\n",
      "343/343 [==============================] - 93s 271ms/step - loss: 0.0131 - accuracy: 0.9971 - precision: 0.9971 - recall: 0.9971 - val_loss: 0.0148 - val_accuracy: 0.9968 - val_precision: 0.9968 - val_recall: 0.9968\n",
      "Epoch 68/200\n",
      "343/343 [==============================] - 92s 269ms/step - loss: 0.0111 - accuracy: 0.9977 - precision: 0.9977 - recall: 0.9977 - val_loss: 0.0147 - val_accuracy: 0.9971 - val_precision: 0.9971 - val_recall: 0.9971\n",
      "Epoch 69/200\n",
      "343/343 [==============================] - 92s 268ms/step - loss: 0.0109 - accuracy: 0.9978 - precision: 0.9978 - recall: 0.9978 - val_loss: 0.0142 - val_accuracy: 0.9973 - val_precision: 0.9973 - val_recall: 0.9973\n",
      "Epoch 70/200\n",
      "343/343 [==============================] - 92s 270ms/step - loss: 0.0116 - accuracy: 0.9976 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.0141 - val_accuracy: 0.9973 - val_precision: 0.9973 - val_recall: 0.9973\n",
      "Epoch 71/200\n",
      "343/343 [==============================] - 92s 268ms/step - loss: 0.0109 - accuracy: 0.9977 - precision: 0.9977 - recall: 0.9977 - val_loss: 0.0148 - val_accuracy: 0.9972 - val_precision: 0.9972 - val_recall: 0.9972\n",
      "Epoch 72/200\n",
      "343/343 [==============================] - 92s 268ms/step - loss: 0.0110 - accuracy: 0.9977 - precision: 0.9977 - recall: 0.9977 - val_loss: 0.0142 - val_accuracy: 0.9974 - val_precision: 0.9974 - val_recall: 0.9974\n",
      "Epoch 73/200\n",
      "343/343 [==============================] - 92s 269ms/step - loss: 0.0108 - accuracy: 0.9978 - precision: 0.9978 - recall: 0.9978 - val_loss: 0.0142 - val_accuracy: 0.9971 - val_precision: 0.9971 - val_recall: 0.9971\n",
      "Epoch 74/200\n",
      "343/343 [==============================] - 92s 268ms/step - loss: 0.0109 - accuracy: 0.9977 - precision: 0.9977 - recall: 0.9977 - val_loss: 0.0144 - val_accuracy: 0.9972 - val_precision: 0.9972 - val_recall: 0.9972\n",
      "Epoch 75/200\n",
      "343/343 [==============================] - 94s 274ms/step - loss: 0.0110 - accuracy: 0.9977 - precision: 0.9977 - recall: 0.9977 - val_loss: 0.0142 - val_accuracy: 0.9973 - val_precision: 0.9973 - val_recall: 0.9973\n",
      "Epoch 76/200\n",
      "343/343 [==============================] - 92s 268ms/step - loss: 0.0111 - accuracy: 0.9977 - precision: 0.9977 - recall: 0.9977 - val_loss: 0.0146 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 77/200\n",
      "343/343 [==============================] - 92s 268ms/step - loss: 0.0110 - accuracy: 0.9977 - precision: 0.9977 - recall: 0.9977 - val_loss: 0.0144 - val_accuracy: 0.9973 - val_precision: 0.9973 - val_recall: 0.9973\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, LSTM, Dropout, Input\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "num_folds = 5\n",
    "verbosity = 1\n",
    "n_classes = 2\n",
    "n_features = X_train_lstm.shape[2]\n",
    "activation = 'relu'\n",
    "batch_size = 1024\n",
    "dropout_rate = 0.2\n",
    "epochs = 500\n",
    "kernel_initializer = 'normal'\n",
    "lstm_units_1 = 50\n",
    "lstm_units_2 = 30\n",
    "lstm_units_3 = 50\n",
    "optimizer = 'Adamax'\n",
    "\n",
    "\n",
    "callback_early_stopping = EarlyStopping(patience=20, mode='min', restore_best_weights=True)\n",
    "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=lstm_units_1, activation=activation, kernel_initializer=kernel_initializer, return_sequences=True, input_shape=(timesteps, features)))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(LSTM(units=lstm_units_2, activation=activation, kernel_initializer=kernel_initializer, return_sequences=True))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(LSTM(units=lstm_units_3, activation=activation, kernel_initializer=kernel_initializer))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    " \n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Training...')\n",
    "\n",
    "history = model.fit(X_train_lstm, y_train_pca, validation_split=0.2, \n",
    "                    callbacks=[callback_early_stopping, callback_reduce_lr],\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=no_epochs,\n",
    "                    verbose=verbosity)\n",
    "\n",
    "# Deerlendirme metriklerini hesapla\n",
    "true_labels = y_test\n",
    "\n",
    "predictions = model.predict(X_test_lstm)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.5f}, Precision: {precision:.5f}, Recall: {recall:.5f}')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(kind='line', xlabel='epochs', figsize=(8, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26eb10ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_matrix(y_true, y_pred, labels=None):\n",
    "    mlm = multilabel_confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    df_performance = pd.DataFrame(index=labels, columns=['accuracy', 'precision', 'recall', 'f1_score'])\n",
    "    for i, label in enumerate(labels):\n",
    "        tn, fp, fn, tp = mlm[i].ravel()\n",
    "        accuracy = (tn + tp) / (tn + fp + fn + tp)\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "\n",
    "        f1_score = 2*precision * recall / (precision + recall)\n",
    "        df_performance.loc[label] = [round(accuracy, 4), round(precision,4), \\\n",
    "                                     round(recall, 4), round(f1_score,4)]\n",
    "    return df_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "612ff942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import cycle\n",
    "def RoC_Curve(y_score, y_resample, labels, title): \n",
    "    y_cat = to_categorical(y_resample)\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    lw = 2\n",
    "    # First aggregate all false positive rates\n",
    "    n_classes = len(labels)\n",
    "#     print('n_classes:', n_classes)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_cat[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_cat.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.4f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label='macro-average ROC curve (area = {0:0.4f})'\n",
    "                   ''.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(fpr[i], tpr[i], lw=lw,\n",
    "                 label=f'ROC curve of class {labels[i]} (area = {roc_auc[i]:0.4f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e46a77ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on training set\n",
    "y_train_pred_prob = model.predict(X_train1)\n",
    "y_test_pred_prob = model.predict(X_test1)\n",
    "y_train_pred = np.argmax(y_train_pred_prob, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58892c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le = preprocessing.LabelEncoder()\n",
    "    \n",
    "y_trainc = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1147057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "cm = confusion_matrix(y_resample, y_train_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c570fa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_).plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c2d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2 = confusion_matrix(y_test_pca, y_test_pred)\n",
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c16f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=le.classes_).plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96f21a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.9648</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.9813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.9987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accuracy precision  recall f1_score\n",
       "0   0.9976    0.9648  0.9984   0.9813\n",
       "1   0.9976    0.9999  0.9976   0.9987"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "y_train_pred_labels = le.inverse_transform(y_train_pred)\n",
    "y_train_labels = le.inverse_transform(y_train)\n",
    "\n",
    "performance = multilabel_matrix(y_train_pred_labels, y_train_labels, labels=le.classes_)\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "baad7bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_labels = le.inverse_transform(y_test_pred) \n",
    "y_test_true_labels = le.inverse_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "faea7ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>0.9602</td>\n",
       "      <td>0.9781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.9985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accuracy precision  recall f1_score\n",
       "0   0.9972    0.9966  0.9602   0.9781\n",
       "1   0.9972    0.9973  0.9998   0.9985"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = multilabel_matrix(y_test_true_labels, y_test_pred_labels, labels=le.classes_)\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "235019f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_true=y_test, y_pred=y_test_pred)\n",
    "#\n",
    "# Print the confusion matrix using Matplotlib\n",
    "#\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Tahmin', fontsize=18)\n",
    "plt.ylabel('Gerek', fontsize=18)\n",
    "plt.title('Karmaklk Matrisi', fontsize=18)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
