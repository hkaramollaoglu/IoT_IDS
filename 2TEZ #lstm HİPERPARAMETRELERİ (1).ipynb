{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "692cfe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b728c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "start = time.time()\n",
    "#read data in chunks of 1 million rows at a time\n",
    "chunk1 = pd.read_csv('I:\\\\verisetleri1\\\\X_train.csv',chunksize=1000000)\n",
    "chunk2 = pd.read_csv('I:\\\\verisetleri1\\\\X_test.csv',chunksize=1000000)\n",
    "chunk3 = pd.read_csv('I:\\\\verisetleri1\\\\y_train.csv',chunksize=1000000)\n",
    "chunk4 = pd.read_csv('I:\\\\verisetleri1\\\\y_test.csv',chunksize=1000000)\n",
    "\n",
    "\n",
    "x_train = pd.concat(chunk1)\n",
    "x_test  = pd.concat(chunk2)\n",
    "y_train = pd.concat(chunk3)\n",
    "y_test  = pd.concat(chunk4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e227676",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= x_train.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d555fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= x_test.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef79ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train= y_train.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d46f2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test= y_test.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54910b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=Y_test['15']\n",
    "Y_train=Y_train['15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5360cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train\n",
    "del x_test\n",
    "del y_train\n",
    "del y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "234fc240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "model=scaler.fit(X_train)\n",
    "X_train=model.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7852dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "model=scaler.fit(X_test)\n",
    "X_test=model.transform(X_test)\n",
    "\n",
    "y_train1 = to_categorical(Y_train, num_classes=2)\n",
    "y_test1 = to_categorical(Y_test, num_classes=2)\n",
    "### reshape input data to LSTM format [samples, time_steps, features]\n",
    "X_train_lstm = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test_lstm = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65f5ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Bidirectional, LSTM, GRU, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40bbf92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed1dc2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1 = to_categorical(Y_train, num_classes=2)\n",
    "y_test1 = to_categorical(Y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f8ad808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "import keras\n",
    "# Conv1D + LSTM\n",
    "from keras.layers.convolutional import Conv1D \n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6024b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4880bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f82cd54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fc871b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score, make_scorer, mean_absolute_percentage_error, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, LSTM, Dropout, Input\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16d93725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametre kombinasyonu ve sonuçlar:\n",
      "Doğruluk skoru: 0.996789\n",
      "Aktivasyon fonksiyonu: relu\n",
      "Kernel başlatma modu: normal\n",
      "LSTM (1. katman) birimleri: 50\n",
      "LSTM (2. katman) birimleri: 30\n",
      "LSTM (3. katman) birimleri: 50\n",
      "Dropout oranı: 0.2\n",
      "Optimizasyon algoritması: Adamax\n",
      "Batch boyutu: 1024\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv  # HalvingGridSearchCV'yi etkinleştirmek için gerekli\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Input\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "\n",
    "# Modeli oluşturma fonksiyonu\n",
    "def create_model(activation='relu', kernel_initializer='uniform', lstm_units_1=10, lstm_units_2=10, lstm_units_3=10, dropout_rate=0.1, optimizer='SGD'):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(None, n_features)))\n",
    "    model.add(LSTM(units=lstm_units_1, return_sequences=True, kernel_initializer=kernel_initializer, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=lstm_units_2, return_sequences=True, kernel_initializer=kernel_initializer, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=lstm_units_3, kernel_initializer=kernel_initializer, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(n_classes, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# KerasClassifier ile modeli sarmalama\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Hiperparametre listesi\n",
    "param_grid = {\n",
    "    'activation': ['relu', 'tanh', 'softmax', 'sigmoid'],\n",
    "    'kernel_initializer': ['uniform', 'normal', 'zero', 'he_normal', 'he_uniform'],\n",
    "    'lstm_units_1': [10, 30, 50, 70],\n",
    "    'lstm_units_2': [10, 30, 50, 70],\n",
    "    'lstm_units_3': [10, 30, 50, 70],\n",
    "    'dropout_rate': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'optimizer': ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'],\n",
    "    'batch_size': [128, 256, 512, 1024],\n",
    "    'epochs': [10]  # Eğitim süresince epoch sayısı\n",
    "}\n",
    "\n",
    "# HalvingGridSearchCV\n",
    "grid = HalvingGridSearchCV(estimator=model, param_grid=param_grid, factor=3, resource='n_samples', max_resources=50, min_resources='exhaust', cv=3, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# En iyi parametreleri ve sonuçları yazdırma\n",
    "print(\"En iyi doğruluk skoru: %f kullanarak %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "\n",
    "best_params = grid_result.best_params_\n",
    "best_score = grid_result.best_score_\n",
    "\n",
    "print(\"\\nEn iyi parametre kombinasyonu ve sonuçlar:\")\n",
    "print(f\"Doğruluk skoru: {best_score:.6f}\")\n",
    "print(f\"Aktivasyon fonksiyonu: {best_params['activation']}\")\n",
    "print(f\"Kernel başlatma modu: {best_params['kernel_initializer']}\")\n",
    "print(f\"LSTM (1. katman) birimleri: {best_params['lstm_units_1']}\")\n",
    "print(f\"LSTM (2. katman) birimleri: {best_params['lstm_units_2']}\")\n",
    "print(f\"LSTM (3. katman) birimleri: {best_params['lstm_units_3']}\")\n",
    "print(f\"Dropout oranı: {best_params['dropout_rate']}\")\n",
    "print(f\"Optimizasyon algoritması: {best_params['optimizer']}\")\n",
    "print(f\"Batch boyutu: {best_params['batch_size']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e444882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
