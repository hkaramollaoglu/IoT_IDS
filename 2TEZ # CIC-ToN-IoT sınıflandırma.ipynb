{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0088fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e9abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "start = time.time()\n",
    "#read data in chunks of 1 million rows at a time\n",
    "chunk1 = pd.read_csv('I:\\\\verisetleri1\\\\CIC-ToN-IoT\\\\X_train.csv',chunksize=1000000)\n",
    "chunk2 = pd.read_csv('I:\\\\verisetleri1\\\\CIC-ToN-IoT\\\\X_test.csv',chunksize=1000000)\n",
    "chunk3 = pd.read_csv('I:\\\\verisetleri1\\\\CIC-ToN-IoT\\\\y_test.csv',chunksize=1000000)\n",
    "chunk4 = pd.read_csv('I:\\\\verisetleri1\\\\CIC-ToN-IoT\\\\y_train.csv',chunksize=1000000)\n",
    "\n",
    "\n",
    "x_train = pd.concat(chunk1)\n",
    "x_test  = pd.concat(chunk2)\n",
    "y_train = pd.concat(chunk3)\n",
    "y_test  = pd.concat(chunk4)\n",
    "\n",
    "X_train= x_train.drop(['Unnamed: 0'], axis=1)\n",
    "X_test= x_test.drop(['Unnamed: 0'], axis=1)\n",
    "Y_train= y_train.drop(['Unnamed: 0'], axis=1)\n",
    "Y_test= y_test.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74cc9f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=Y_test['15']\n",
    "Y_train=Y_train['15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3ead673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e1d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1 = to_categorical(Y_train, num_classes=2)\n",
    "y_test1 = to_categorical(Y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "854cb14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### reshape input data to LSTM format [samples, time_steps, features]\n",
    "X_train_lstm = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test_lstm = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69bb8de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "import keras\n",
    "from keras.layers.convolutional import Conv1D \n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a2cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87522227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0adaa9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eeace62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import cycle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a139c25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training...\n",
      "Epoch 1/500\n",
      "2927/2927 [==============================] - 62s 17ms/step - loss: 0.0603 - accuracy: 0.9809 - val_loss: 0.0331 - val_accuracy: 0.9901\n",
      "Epoch 2/500\n",
      "2927/2927 [==============================] - 47s 16ms/step - loss: 0.0322 - accuracy: 0.9902 - val_loss: 0.0261 - val_accuracy: 0.9915\n",
      "Epoch 3/500\n",
      "2927/2927 [==============================] - 46s 16ms/step - loss: 0.0272 - accuracy: 0.9909 - val_loss: 0.0237 - val_accuracy: 0.9914\n",
      "Epoch 4/500\n",
      "2927/2927 [==============================] - 46s 16ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.0219 - val_accuracy: 0.9919\n",
      "Epoch 5/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 0.0212 - val_accuracy: 0.9918\n",
      "Epoch 6/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0226 - accuracy: 0.9917 - val_loss: 0.0200 - val_accuracy: 0.9923\n",
      "Epoch 7/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0218 - accuracy: 0.9919 - val_loss: 0.0195 - val_accuracy: 0.9926\n",
      "Epoch 8/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0212 - accuracy: 0.9921 - val_loss: 0.0194 - val_accuracy: 0.9922\n",
      "Epoch 9/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0208 - accuracy: 0.9922 - val_loss: 0.0194 - val_accuracy: 0.9924\n",
      "Epoch 10/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0205 - accuracy: 0.9923 - val_loss: 0.0203 - val_accuracy: 0.9922\n",
      "Epoch 11/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0203 - accuracy: 0.9923 - val_loss: 0.0190 - val_accuracy: 0.9927\n",
      "Epoch 12/500\n",
      "2927/2927 [==============================] - 53s 18ms/step - loss: 0.0199 - accuracy: 0.9924 - val_loss: 0.0186 - val_accuracy: 0.9926\n",
      "Epoch 13/500\n",
      "2927/2927 [==============================] - 46s 16ms/step - loss: 0.0198 - accuracy: 0.9924 - val_loss: 0.0181 - val_accuracy: 0.9928\n",
      "Epoch 14/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0196 - accuracy: 0.9925 - val_loss: 0.0181 - val_accuracy: 0.9927\n",
      "Epoch 15/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0194 - accuracy: 0.9925 - val_loss: 0.0204 - val_accuracy: 0.9914\n",
      "Epoch 16/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0193 - accuracy: 0.9925 - val_loss: 0.0180 - val_accuracy: 0.9929\n",
      "Epoch 17/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0192 - accuracy: 0.9926 - val_loss: 0.0187 - val_accuracy: 0.9928\n",
      "Epoch 18/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0191 - accuracy: 0.9926 - val_loss: 0.0185 - val_accuracy: 0.9927\n",
      "Epoch 19/500\n",
      "2927/2927 [==============================] - 46s 16ms/step - loss: 0.0190 - accuracy: 0.9926 - val_loss: 0.0181 - val_accuracy: 0.9928\n",
      "Epoch 20/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0189 - accuracy: 0.9926 - val_loss: 0.0183 - val_accuracy: 0.9928\n",
      "Epoch 21/500\n",
      "2927/2927 [==============================] - 46s 16ms/step - loss: 0.0188 - accuracy: 0.9927 - val_loss: 0.0176 - val_accuracy: 0.9929\n",
      "Epoch 22/500\n",
      "2927/2927 [==============================] - 46s 16ms/step - loss: 0.0187 - accuracy: 0.9927 - val_loss: 0.0175 - val_accuracy: 0.9929\n",
      "Epoch 23/500\n",
      "2927/2927 [==============================] - 46s 16ms/step - loss: 0.0186 - accuracy: 0.9927 - val_loss: 0.0175 - val_accuracy: 0.9929\n",
      "Epoch 24/500\n",
      "2927/2927 [==============================] - 45s 16ms/step - loss: 0.0186 - accuracy: 0.9928 - val_loss: 0.0178 - val_accuracy: 0.9929\n",
      "Epoch 25/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0185 - accuracy: 0.9928 - val_loss: 0.0174 - val_accuracy: 0.9929\n",
      "Epoch 26/500\n",
      "2927/2927 [==============================] - 45s 16ms/step - loss: 0.0185 - accuracy: 0.9928 - val_loss: 0.0177 - val_accuracy: 0.9928\n",
      "Epoch 27/500\n",
      "2927/2927 [==============================] - 46s 16ms/step - loss: 0.0183 - accuracy: 0.9928 - val_loss: 0.0173 - val_accuracy: 0.9930\n",
      "Epoch 28/500\n",
      "2927/2927 [==============================] - 46s 16ms/step - loss: 0.0183 - accuracy: 0.9928 - val_loss: 0.0174 - val_accuracy: 0.9931\n",
      "Epoch 29/500\n",
      "2927/2927 [==============================] - 46s 16ms/step - loss: 0.0183 - accuracy: 0.9929 - val_loss: 0.0182 - val_accuracy: 0.9927\n",
      "Epoch 30/500\n",
      "2927/2927 [==============================] - 48s 16ms/step - loss: 0.0182 - accuracy: 0.9928 - val_loss: 0.0178 - val_accuracy: 0.9928\n",
      "Epoch 31/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0181 - accuracy: 0.9929 - val_loss: 0.0172 - val_accuracy: 0.9932\n",
      "Epoch 32/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0181 - accuracy: 0.9929 - val_loss: 0.0175 - val_accuracy: 0.9929\n",
      "Epoch 33/500\n",
      "2927/2927 [==============================] - 48s 16ms/step - loss: 0.0181 - accuracy: 0.9929 - val_loss: 0.0176 - val_accuracy: 0.9928\n",
      "Epoch 34/500\n",
      "2927/2927 [==============================] - 49s 17ms/step - loss: 0.0180 - accuracy: 0.9929 - val_loss: 0.0171 - val_accuracy: 0.9930\n",
      "Epoch 35/500\n",
      "2927/2927 [==============================] - 48s 16ms/step - loss: 0.0181 - accuracy: 0.9929 - val_loss: 0.0186 - val_accuracy: 0.9927\n",
      "Epoch 36/500\n",
      "2927/2927 [==============================] - 47s 16ms/step - loss: 0.0180 - accuracy: 0.9929 - val_loss: 0.0175 - val_accuracy: 0.9930\n",
      "Epoch 37/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0179 - accuracy: 0.9929 - val_loss: 0.0201 - val_accuracy: 0.9923\n",
      "Epoch 38/500\n",
      "2927/2927 [==============================] - 45s 16ms/step - loss: 0.0178 - accuracy: 0.9929 - val_loss: 0.0173 - val_accuracy: 0.9930\n",
      "Epoch 39/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0179 - accuracy: 0.9929 - val_loss: 0.0174 - val_accuracy: 0.9930\n",
      "Epoch 40/500\n",
      "2927/2927 [==============================] - 50s 17ms/step - loss: 0.0178 - accuracy: 0.9930 - val_loss: 0.0171 - val_accuracy: 0.9930\n",
      "Epoch 41/500\n",
      "2927/2927 [==============================] - 48s 16ms/step - loss: 0.0178 - accuracy: 0.9929 - val_loss: 0.0173 - val_accuracy: 0.9929\n",
      "Epoch 42/500\n",
      "2927/2927 [==============================] - 46s 16ms/step - loss: 0.0177 - accuracy: 0.9929 - val_loss: 0.0172 - val_accuracy: 0.9931\n",
      "Epoch 43/500\n",
      "2927/2927 [==============================] - 47s 16ms/step - loss: 0.0176 - accuracy: 0.9930 - val_loss: 0.0173 - val_accuracy: 0.9930\n",
      "Epoch 44/500\n",
      "2927/2927 [==============================] - 49s 17ms/step - loss: 0.0176 - accuracy: 0.9930 - val_loss: 0.0170 - val_accuracy: 0.9931\n",
      "Epoch 45/500\n",
      "2927/2927 [==============================] - 49s 17ms/step - loss: 0.0176 - accuracy: 0.9930 - val_loss: 0.0172 - val_accuracy: 0.9930\n",
      "Epoch 46/500\n",
      "2927/2927 [==============================] - 48s 16ms/step - loss: 0.0176 - accuracy: 0.9930 - val_loss: 0.0172 - val_accuracy: 0.9931\n",
      "Epoch 47/500\n",
      "2927/2927 [==============================] - 48s 16ms/step - loss: 0.0176 - accuracy: 0.9930 - val_loss: 0.0173 - val_accuracy: 0.9930\n",
      "Epoch 48/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0175 - accuracy: 0.9930 - val_loss: 0.0173 - val_accuracy: 0.9930\n",
      "Epoch 49/500\n",
      "2927/2927 [==============================] - 47s 16ms/step - loss: 0.0176 - accuracy: 0.9930 - val_loss: 0.0171 - val_accuracy: 0.9931\n",
      "Epoch 50/500\n",
      "2927/2927 [==============================] - 48s 17ms/step - loss: 0.0175 - accuracy: 0.9930 - val_loss: 0.0183 - val_accuracy: 0.9927\n",
      "Epoch 51/500\n",
      "2927/2927 [==============================] - 47s 16ms/step - loss: 0.0175 - accuracy: 0.9930 - val_loss: 0.0178 - val_accuracy: 0.9930\n",
      "Epoch 52/500\n",
      "2927/2927 [==============================] - 46s 16ms/step - loss: 0.0175 - accuracy: 0.9930 - val_loss: 0.0170 - val_accuracy: 0.9932\n",
      "Epoch 53/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0174 - accuracy: 0.9931 - val_loss: 0.0173 - val_accuracy: 0.9931\n",
      "Epoch 54/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0174 - accuracy: 0.9930 - val_loss: 0.0174 - val_accuracy: 0.9931\n",
      "Epoch 55/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0174 - accuracy: 0.9931 - val_loss: 0.0180 - val_accuracy: 0.9927\n",
      "Epoch 56/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0174 - accuracy: 0.9930 - val_loss: 0.0173 - val_accuracy: 0.9931\n",
      "Epoch 57/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0174 - accuracy: 0.9931 - val_loss: 0.0172 - val_accuracy: 0.9930\n",
      "Epoch 58/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0173 - accuracy: 0.9931 - val_loss: 0.0174 - val_accuracy: 0.9930\n",
      "Epoch 59/500\n",
      "2927/2927 [==============================] - 47s 16ms/step - loss: 0.0172 - accuracy: 0.9930 - val_loss: 0.0174 - val_accuracy: 0.9930\n",
      "Epoch 60/500\n",
      "2927/2927 [==============================] - 46s 16ms/step - loss: 0.0174 - accuracy: 0.9930 - val_loss: 0.0168 - val_accuracy: 0.9932\n",
      "Epoch 61/500\n",
      "2927/2927 [==============================] - 49s 17ms/step - loss: 0.0173 - accuracy: 0.9931 - val_loss: 0.0171 - val_accuracy: 0.9931\n",
      "Epoch 62/500\n",
      "2927/2927 [==============================] - 55s 19ms/step - loss: 0.0174 - accuracy: 0.9930 - val_loss: 0.0173 - val_accuracy: 0.9928\n",
      "Epoch 63/500\n",
      "2927/2927 [==============================] - 45s 16ms/step - loss: 0.0173 - accuracy: 0.9930 - val_loss: 0.0170 - val_accuracy: 0.9931\n",
      "Epoch 64/500\n",
      "2927/2927 [==============================] - 50s 17ms/step - loss: 0.0173 - accuracy: 0.9931 - val_loss: 0.0167 - val_accuracy: 0.9931\n",
      "Epoch 65/500\n",
      "2927/2927 [==============================] - 48s 16ms/step - loss: 0.0172 - accuracy: 0.9931 - val_loss: 0.0166 - val_accuracy: 0.9932\n",
      "Epoch 66/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0172 - accuracy: 0.9931 - val_loss: 0.0167 - val_accuracy: 0.9932\n",
      "Epoch 67/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0171 - accuracy: 0.9931 - val_loss: 0.0169 - val_accuracy: 0.9932\n",
      "Epoch 68/500\n",
      "2927/2927 [==============================] - 47s 16ms/step - loss: 0.0172 - accuracy: 0.9931 - val_loss: 0.0171 - val_accuracy: 0.9931\n",
      "Epoch 69/500\n",
      "2927/2927 [==============================] - 47s 16ms/step - loss: 0.0171 - accuracy: 0.9931 - val_loss: 0.0172 - val_accuracy: 0.9932\n",
      "Epoch 70/500\n",
      "2927/2927 [==============================] - 47s 16ms/step - loss: 0.0171 - accuracy: 0.9931 - val_loss: 0.0172 - val_accuracy: 0.9930\n",
      "Epoch 71/500\n",
      "2927/2927 [==============================] - 46s 16ms/step - loss: 0.0172 - accuracy: 0.9931 - val_loss: 0.0168 - val_accuracy: 0.9931\n",
      "Epoch 72/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0171 - accuracy: 0.9931 - val_loss: 0.0168 - val_accuracy: 0.9932\n",
      "Epoch 73/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0170 - accuracy: 0.9931 - val_loss: 0.0167 - val_accuracy: 0.9931\n",
      "Epoch 74/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0171 - accuracy: 0.9931 - val_loss: 0.0167 - val_accuracy: 0.9932\n",
      "Epoch 75/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0171 - accuracy: 0.9931 - val_loss: 0.0165 - val_accuracy: 0.9933\n",
      "Epoch 76/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0170 - accuracy: 0.9931 - val_loss: 0.0170 - val_accuracy: 0.9932\n",
      "Epoch 77/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0171 - accuracy: 0.9931 - val_loss: 0.0169 - val_accuracy: 0.9933\n",
      "Epoch 78/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0170 - accuracy: 0.9931 - val_loss: 0.0172 - val_accuracy: 0.9931\n",
      "Epoch 79/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0170 - accuracy: 0.9932 - val_loss: 0.0168 - val_accuracy: 0.9930\n",
      "Epoch 80/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0170 - accuracy: 0.9931 - val_loss: 0.0167 - val_accuracy: 0.9931\n",
      "Epoch 81/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0170 - accuracy: 0.9931 - val_loss: 0.0175 - val_accuracy: 0.9930\n",
      "Epoch 82/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0170 - accuracy: 0.9931 - val_loss: 0.0178 - val_accuracy: 0.9926\n",
      "Epoch 83/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0170 - accuracy: 0.9931 - val_loss: 0.0169 - val_accuracy: 0.9933\n",
      "Epoch 84/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0169 - accuracy: 0.9931 - val_loss: 0.0168 - val_accuracy: 0.9931\n",
      "Epoch 85/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0170 - accuracy: 0.9931 - val_loss: 0.0171 - val_accuracy: 0.9930\n",
      "Epoch 86/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0169 - accuracy: 0.9931 - val_loss: 0.0170 - val_accuracy: 0.9931\n",
      "Epoch 87/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0169 - accuracy: 0.9931 - val_loss: 0.0165 - val_accuracy: 0.9932\n",
      "Epoch 88/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0169 - accuracy: 0.9932 - val_loss: 0.0168 - val_accuracy: 0.9932\n",
      "Epoch 89/500\n",
      "2927/2927 [==============================] - 44s 15ms/step - loss: 0.0169 - accuracy: 0.9931 - val_loss: 0.0168 - val_accuracy: 0.9932\n",
      "Epoch 90/500\n",
      "2927/2927 [==============================] - 45s 16ms/step - loss: 0.0169 - accuracy: 0.9932 - val_loss: 0.0169 - val_accuracy: 0.9930\n",
      "Epoch 91/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.0170 - val_accuracy: 0.9931\n",
      "Epoch 92/500\n",
      "2927/2927 [==============================] - 56s 19ms/step - loss: 0.0169 - accuracy: 0.9931 - val_loss: 0.0167 - val_accuracy: 0.9932\n",
      "Epoch 93/500\n",
      "2927/2927 [==============================] - 49s 17ms/step - loss: 0.0169 - accuracy: 0.9932 - val_loss: 0.0170 - val_accuracy: 0.9931\n",
      "Epoch 94/500\n",
      "2927/2927 [==============================] - 46s 16ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.0166 - val_accuracy: 0.9932\n",
      "Epoch 95/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.0171 - val_accuracy: 0.9930\n",
      "Epoch 96/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.0167 - val_accuracy: 0.9932\n",
      "Epoch 97/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0167 - accuracy: 0.9932 - val_loss: 0.0167 - val_accuracy: 0.9931\n",
      "Epoch 98/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.0171 - val_accuracy: 0.9932\n",
      "Epoch 99/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.0166 - val_accuracy: 0.9933\n",
      "Epoch 100/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.0171 - val_accuracy: 0.9932\n",
      "Epoch 101/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0167 - accuracy: 0.9932 - val_loss: 0.0173 - val_accuracy: 0.9929\n",
      "Epoch 102/500\n",
      "2927/2927 [==============================] - 45s 15ms/step - loss: 0.0167 - accuracy: 0.9932 - val_loss: 0.0166 - val_accuracy: 0.9933\n",
      "Epoch 103/500\n",
      "2927/2927 [==============================] - 49s 17ms/step - loss: 0.0167 - accuracy: 0.9932 - val_loss: 0.0167 - val_accuracy: 0.9932\n",
      "Epoch 104/500\n",
      "2927/2927 [==============================] - 49s 17ms/step - loss: 0.0167 - accuracy: 0.9932 - val_loss: 0.0171 - val_accuracy: 0.9931\n",
      "Epoch 105/500\n",
      "2927/2927 [==============================] - 47s 16ms/step - loss: 0.0167 - accuracy: 0.9932 - val_loss: 0.0168 - val_accuracy: 0.9931\n",
      "Epoch 106/500\n",
      "2927/2927 [==============================] - 51s 17ms/step - loss: 0.0167 - accuracy: 0.9932 - val_loss: 0.0165 - val_accuracy: 0.9933\n",
      "Epoch 107/500\n",
      "2927/2927 [==============================] - 50s 17ms/step - loss: 0.0167 - accuracy: 0.9932 - val_loss: 0.0165 - val_accuracy: 0.9932\n",
      "Accuracy: 0.99344, Precision: 0.99347, Recall: 0.99344\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, LSTM, Dropout, Input\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "num_folds = 5\n",
    "verbosity = 1\n",
    "n_classes = 2\n",
    "n_features = X_train_lstm.shape[2]\n",
    "activation = 'relu'\n",
    "batch_size = 1024\n",
    "dropout_rate = 0.2\n",
    "epochs = 500\n",
    "kernel_initializer = 'normal'\n",
    "lstm_units_1 = 50\n",
    "lstm_units_2 = 30\n",
    "lstm_units_3 = 50\n",
    "optimizer = 'Adamax'\n",
    "\n",
    "\n",
    "inputs = X_train_lstm\n",
    "targets = Y_train\n",
    "\n",
    "callback_early_stopping = EarlyStopping(patience=20, mode='min', restore_best_weights=True)\n",
    "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    K.clear_session()  # Clear previous model sessions\n",
    "    \n",
    "     # Modeli oluşturma\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=lstm_units_1, activation=activation, kernel_initializer=kernel_initializer, return_sequences=True, input_shape=(timesteps, features)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=lstm_units_2, activation=activation, kernel_initializer=kernel_initializer, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=lstm_units_3, activation=activation, kernel_initializer=kernel_initializer))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "    # Modeli derleme\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    history = model.fit(inputs[train], targets[train], validation_split=0.2, \n",
    "                        callbacks=[callback_early_stopping, callback_reduce_lr],\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=no_epochs,\n",
    "                        verbose=verbosity)\n",
    "\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=1)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "    # Değerlendirme metriklerini hesapla\n",
    "    true_labels = targets[test]\n",
    "\n",
    "    predictions = model.predict(inputs[test])\n",
    "    predicted_labels = np.argmax(predictions, axis=1)  # Varsayılan olarak sınıfların en yüksek olasılığına göre tahminler\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.5f}, Precision: {precision:.5f}, Recall: {recall:.5f}')\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bad41784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_matrix(y_true, y_pred, labels=None):\n",
    "    mlm = multilabel_confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    df_performance = pd.DataFrame(index=labels, columns=['accuracy', 'precision', 'recall', 'f1_score'])\n",
    "    for i, label in enumerate(labels):\n",
    "        tn, fp, fn, tp = mlm[i].ravel()\n",
    "        accuracy = (tn + tp) / (tn + fp + fn + tp)\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "\n",
    "        f1_score = 2*precision * recall / (precision + recall)\n",
    "        df_performance.loc[label] = [round(accuracy, 4), round(precision,4), \\\n",
    "                                     round(recall, 4), round(f1_score,4)]\n",
    "    return df_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c23d13a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import cycle\n",
    "def RoC_Curve(y_score, y_resample, labels, title): \n",
    "    y_cat = to_categorical(y_resample)\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    lw = 2\n",
    "    # First aggregate all false positive rates\n",
    "    n_classes = len(labels)\n",
    "#     print('n_classes:', n_classes)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_cat[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_cat.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.4f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label='macro-average ROC curve (area = {0:0.4f})'\n",
    "                   ''.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(fpr[i], tpr[i], lw=lw,\n",
    "                 label=f'ROC curve of class {labels[i]} (area = {roc_auc[i]:0.4f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be9af588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on training set\n",
    "y_train_pred_prob = model.predict(X_train_lstm)\n",
    "y_test_pred_prob = model.predict(X_test_lstm)\n",
    "y_train_pred = np.argmax(y_train_pred_prob, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c624f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le = preprocessing.LabelEncoder()\n",
    "    \n",
    "y_trainc = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bc83fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.9899</td>\n",
       "      <td>0.9938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accuracy precision  recall f1_score\n",
       "0   0.9934    0.9885  0.9974    0.993\n",
       "1   0.9934    0.9977  0.9899   0.9938"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "y_train_pred_labels = le.inverse_transform(y_train_pred)\n",
    "y_train_labels = le.inverse_transform(y_train)\n",
    "\n",
    "performance = multilabel_matrix(y_train_pred_labels, y_train_labels, labels=le.classes_)\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df1c84c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.9899</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.9938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accuracy precision  recall f1_score\n",
       "0   0.9934    0.9975  0.9885    0.993\n",
       "1   0.9934    0.9899  0.9978   0.9938"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_labels = le.inverse_transform(y_test_pred)\n",
    "y_test_true_labels = le.inverse_transform(y_test)\n",
    "performance = multilabel_matrix(y_test_true_labels, y_test_pred_labels, labels=le.classes_)\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7aab40d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41854333877563477\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "performance = multilabel_matrix(y_test_true_labels, y_test_pred_labels, labels=le.classes_)\n",
    "performance\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e40b9811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_true=y_test, y_pred=y_test_pred)\n",
    "#\n",
    "# Print the confusion matrix using Matplotlib\n",
    "#\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Tahmin', fontsize=18)\n",
    "plt.ylabel('Gerçek', fontsize=18)\n",
    "plt.title('Karmaşıklık Matrisi', fontsize=18)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
