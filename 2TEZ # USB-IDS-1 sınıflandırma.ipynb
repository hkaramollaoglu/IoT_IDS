{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a431a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "start = time.time()\n",
    "#read data in chunks of 1 million rows at a time\n",
    "chunk1 = pd.read_csv('I:\\\\verisetleri1\\\\USB-IDS1\\\\X_train.csv',chunksize=1000000)\n",
    "chunk2 = pd.read_csv('I:\\\\verisetleri1\\\\USB-IDS1\\\\X_test.csv',chunksize=1000000)\n",
    "chunk3 = pd.read_csv('I:\\\\verisetleri1\\\\USB-IDS1\\\\y_test.csv',chunksize=1000000)\n",
    "chunk4 = pd.read_csv('I:\\\\verisetleri1\\\\USB-IDS1\\\\y_train.csv',chunksize=1000000)\n",
    "\n",
    "\n",
    "x_train = pd.concat(chunk1)\n",
    "x_test  = pd.concat(chunk2)\n",
    "y_train = pd.concat(chunk3)\n",
    "y_test  = pd.concat(chunk4)\n",
    "\n",
    "X_train= x_train.drop(['Unnamed: 0'], axis=1)\n",
    "X_test= x_test.drop(['Unnamed: 0'], axis=1)\n",
    "Y_train= y_train.drop(['Unnamed: 0'], axis=1)\n",
    "Y_test= y_test.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "742d7339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a51bcaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "import keras\n",
    "from keras.layers.convolutional import Conv1D \n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c984115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4499465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b9e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "data_corr=result.corr()\n",
    "sns.heatmap(data_corr, cmap = 'coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b2e45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "import keras\n",
    "from keras.layers.convolutional import Conv1D,MaxPooling1D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adaa1543",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad6069",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resample = X_resample.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5678f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb994cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_train1 = to_categorical(Y_train, num_classes=2)\n",
    "y_test1 = to_categorical(Y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13768753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train: (3369368, 1, 6)\n",
      "shape of X_test: (1444027, 1, 6)\n",
      "shape of X_train: (3369368, 1, 6)\n",
      "shape of X_test: (1444027, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "### reshape input data to LSTM format [samples, time_steps, features]\n",
    "X_train_lstm = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test_lstm = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "print(f\"shape of X_train:\", X_train_lstm.shape)\n",
    "print(f\"shape of X_test:\", X_test_lstm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79644055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52d4f755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training...\n",
      "------------------------------------------------------------------------\n",
      "Training...\n",
      "Epoch 1/500\n",
      "Epoch 1/500\n",
      "2633/2633 [==============================] - 61s 18ms/step - loss: 0.0196 - accuracy: 0.9977 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
      "2633/2633 [==============================] - 61s 18ms/step - loss: 0.0196 - accuracy: 0.9977 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
      "Epoch 2/500\n",
      "   1/2633 [..............................] - ETA: 49s - loss: 0.0010 - accuracy: 1.0000Epoch 2/500\n",
      "2633/2633 [==============================] - 45s 17ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
      "2633/2633 [==============================] - 45s 17ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
      "Epoch 3/500\n",
      "   1/2633 [..............................] - ETA: 37s - loss: 6.3023e-05 - accuracy: 1.0000Epoch 3/500\n",
      "2633/2633 [==============================] - 48s 18ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 9.3269e-04 - val_accuracy: 0.9998\n",
      "2633/2633 [==============================] - 48s 18ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 9.3269e-04 - val_accuracy: 0.9998\n",
      "Epoch 4/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 3.6492e-05 - accuracy: 1.0000Epoch 4/500\n",
      "2633/2633 [==============================] - 46s 17ms/step - loss: 9.7874e-04 - accuracy: 0.9998 - val_loss: 7.5650e-04 - val_accuracy: 0.9999\n",
      "2633/2633 [==============================] - 46s 17ms/step - loss: 9.7874e-04 - accuracy: 0.9998 - val_loss: 7.5650e-04 - val_accuracy: 0.9999\n",
      "Epoch 5/500\n",
      "   1/2633 [..............................] - ETA: 39s - loss: 2.4015e-04 - accuracy: 1.0000Epoch 5/500\n",
      "2633/2633 [==============================] - 46s 18ms/step - loss: 8.6535e-04 - accuracy: 0.9998 - val_loss: 7.2900e-04 - val_accuracy: 0.9999\n",
      "2633/2633 [==============================] - 46s 18ms/step - loss: 8.6535e-04 - accuracy: 0.9998 - val_loss: 7.2900e-04 - val_accuracy: 0.9999\n",
      "Epoch 6/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 4.8862e-05 - accuracy: 1.0000Epoch 6/500\n",
      "2633/2633 [==============================] - 42s 16ms/step - loss: 7.6790e-04 - accuracy: 0.9999 - val_loss: 6.3909e-04 - val_accuracy: 0.9999\n",
      "2633/2633 [==============================] - 42s 16ms/step - loss: 7.6790e-04 - accuracy: 0.9999 - val_loss: 6.3909e-04 - val_accuracy: 0.9999\n",
      "Epoch 7/500\n",
      "   1/2633 [..............................] - ETA: 52s - loss: 7.1331e-05 - accuracy: 1.0000Epoch 7/500\n",
      "2633/2633 [==============================] - 43s 16ms/step - loss: 6.7863e-04 - accuracy: 0.9999 - val_loss: 5.5629e-04 - val_accuracy: 0.9999\n",
      "2633/2633 [==============================] - 43s 16ms/step - loss: 6.7863e-04 - accuracy: 0.9999 - val_loss: 5.5629e-04 - val_accuracy: 0.9999\n",
      "Epoch 8/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 1.1535e-04 - accuracy: 1.0000Epoch 8/500\n",
      "2633/2633 [==============================] - 41s 16ms/step - loss: 6.0179e-04 - accuracy: 0.9999 - val_loss: 4.6987e-04 - val_accuracy: 0.9999\n",
      "2633/2633 [==============================] - 41s 16ms/step - loss: 6.0179e-04 - accuracy: 0.9999 - val_loss: 4.6987e-04 - val_accuracy: 0.9999\n",
      "Epoch 9/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 3.0173e-04 - accuracy: 1.0000Epoch 9/500\n",
      "2633/2633 [==============================] - 42s 16ms/step - loss: 5.5063e-04 - accuracy: 0.9999 - val_loss: 4.5372e-04 - val_accuracy: 0.9999\n",
      "2633/2633 [==============================] - 42s 16ms/step - loss: 5.5063e-04 - accuracy: 0.9999 - val_loss: 4.5372e-04 - val_accuracy: 0.9999\n",
      "Epoch 10/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 1.8076e-05 - accuracy: 1.0000Epoch 10/500\n",
      "2633/2633 [==============================] - 43s 16ms/step - loss: 4.6768e-04 - accuracy: 0.9999 - val_loss: 3.9894e-04 - val_accuracy: 0.9999\n",
      "2633/2633 [==============================] - 43s 16ms/step - loss: 4.6768e-04 - accuracy: 0.9999 - val_loss: 3.9894e-04 - val_accuracy: 0.9999\n",
      "Epoch 11/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 1.2407e-04 - accuracy: 1.0000Epoch 11/500\n",
      "2633/2633 [==============================] - 44s 17ms/step - loss: 4.4115e-04 - accuracy: 0.9999 - val_loss: 3.6769e-04 - val_accuracy: 0.9999\n",
      "2633/2633 [==============================] - 44s 17ms/step - loss: 4.4115e-04 - accuracy: 0.9999 - val_loss: 3.6769e-04 - val_accuracy: 0.9999\n",
      "Epoch 12/500\n",
      "  38/2633 [..............................] - ETA: 38s - loss: 5.2526e-04 - accuracy: 0.9999Epoch 12/500\n",
      "2633/2633 [==============================] - 43s 16ms/step - loss: 3.7629e-04 - accuracy: 0.9999 - val_loss: 3.1401e-04 - val_accuracy: 0.9999\n",
      "2633/2633 [==============================] - 43s 16ms/step - loss: 3.7629e-04 - accuracy: 0.9999 - val_loss: 3.1401e-04 - val_accuracy: 0.9999\n",
      "Epoch 13/500\n",
      "   1/2633 [..............................] - ETA: 39s - loss: 3.8760e-05 - accuracy: 1.0000Epoch 13/500\n",
      "2633/2633 [==============================] - 57s 21ms/step - loss: 3.2623e-04 - accuracy: 0.9999 - val_loss: 2.7589e-04 - val_accuracy: 0.9999\n",
      "2633/2633 [==============================] - 57s 21ms/step - loss: 3.2623e-04 - accuracy: 0.9999 - val_loss: 2.7589e-04 - val_accuracy: 0.9999\n",
      "Epoch 14/500\n",
      "   1/2633 [..............................] - ETA: 45s - loss: 2.6287e-05 - accuracy: 1.0000Epoch 14/500\n",
      "2633/2633 [==============================] - 51s 19ms/step - loss: 2.9766e-04 - accuracy: 0.9999 - val_loss: 2.3626e-04 - val_accuracy: 0.9999\n",
      "2633/2633 [==============================] - 51s 19ms/step - loss: 2.9766e-04 - accuracy: 0.9999 - val_loss: 2.3626e-04 - val_accuracy: 0.9999\n",
      "Epoch 15/500\n",
      "   1/2633 [..............................] - ETA: 40s - loss: 8.4335e-06 - accuracy: 1.0000Epoch 15/500\n",
      "2633/2633 [==============================] - 58s 22ms/step - loss: 2.8468e-04 - accuracy: 0.9999 - val_loss: 2.0111e-04 - val_accuracy: 0.9999 loss: 2.8431e-04 -  - ETA: 0s - loss: 2.8229e-04 - accuracy - ETA: 0s - los - ETA: 1s - loss: 2.8463e-04 - accuracy:  - ETA: 1s - loss: 2.8431e-04 -  - ETA: 0s - loss: 2.8229e-04 - accuracy - ETA: 0s - loss: 2.8411e\n",
      "2633/2633 [==============================] - 58s 22ms/step - loss: 2.8468e-04 - accuracy: 0.9999 - val_loss: 2.0111e-04 - val_accuracy: 0.9999\n",
      "Epoch 16/500\n",
      "   1/2633 [..............................] - ETA: 26s - loss: 6.6788e-04 - accuracy: 1.0000Epoch 16/500\n",
      "2633/2633 [==============================] - 50s 19ms/step - loss: 2.4470e-04 - accuracy: 0.9999 - val_loss: 1.7674e-04 - val_accuracy: 0.9999\n",
      "2633/2633 [==============================] - 50s 19ms/step - loss: 2.4470e-04 - accuracy: 0.9999 - val_loss: 1.7674e-04 - val_accuracy: 0.9999\n",
      "Epoch 17/500\n",
      "  15/2633 [..............................] - ETA: 1:07 - loss: 2.7253e-04 - accuracy: 0.9999Epoch 17/500\n",
      "2633/2633 [==============================] - 49s 19ms/step - loss: 2.2091e-04 - accuracy: 0.9999 - val_loss: 1.5526e-04 - val_accuracy: 0.9999\n",
      "2633/2633 [==============================] - 49s 19ms/step - loss: 2.2091e-04 - accuracy: 0.9999 - val_loss: 1.5526e-04 - val_accuracy: 0.9999\n",
      "Epoch 18/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 1.5157e-05 - accuracy: 1.0000Epoch 18/500\n",
      "2633/2633 [==============================] - 47s 18ms/step - loss: 2.0439e-04 - accuracy: 0.9999 - val_loss: 1.5320e-04 - val_accuracy: 0.9999=================>.] -\n",
      "2633/2633 [==============================] - 47s 18ms/step - loss: 2.0439e-04 - accuracy: 0.9999 - val_loss: 1.5320e-04 - val_accuracy: 0.9999\n",
      "Epoch 19/500\n",
      "   1/2633 [..............................] - ETA: 39s - loss: 8.2575e-06 - accuracy: 1.0000Epoch 19/500\n",
      "2633/2633 [==============================] - 49s 19ms/step - loss: 2.0191e-04 - accuracy: 0.9999 - val_loss: 1.5090e-04 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 49s 19ms/step - loss: 2.0191e-04 - accuracy: 0.9999 - val_loss: 1.5090e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "   1/2633 [..............................] - ETA: 39s - loss: 2.1741e-05 - accuracy: 1.0000Epoch 20/500\n",
      "2633/2633 [==============================] - 45s 17ms/step - loss: 1.9904e-04 - accuracy: 0.9999 - val_loss: 1.3014e-04 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 45s 17ms/step - loss: 1.9904e-04 - accuracy: 0.9999 - val_loss: 1.3014e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 2.1305e-05 - accuracy: 1.0000Epoch 21/500\n",
      "2633/2633 [==============================] - 51s 20ms/step - loss: 1.8936e-04 - accuracy: 0.9999 - val_loss: 1.0924e-04 - val_accuracy: 1.00000s - loss:\n",
      "2633/2633 [==============================] - 51s 20ms/step - loss: 1.8936e-04 - accuracy: 0.9999 - val_loss: 1.0924e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "   1/2633 [..............................] - ETA: 45s - loss: 9.0630e-06 - accuracy: 1.0000Epoch 22/500\n",
      "2633/2633 [==============================] - 53s 20ms/step - loss: 1.6435e-04 - accuracy: 1.0000 - val_loss: 1.0802e-04 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 53s 20ms/step - loss: 1.6435e-04 - accuracy: 1.0000 - val_loss: 1.0802e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 7.2986e-06 - accuracy: 1.0000Epoch 23/500\n",
      "2633/2633 [==============================] - 44s 17ms/step - loss: 1.5901e-04 - accuracy: 1.0000 - val_loss: 1.1001e-04 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 44s 17ms/step - loss: 1.5901e-04 - accuracy: 1.0000 - val_loss: 1.1001e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 4.7589e-06 - accuracy: 1.0000Epoch 24/500\n",
      "2633/2633 [==============================] - 49s 19ms/step - loss: 1.7869e-04 - accuracy: 0.9999 - val_loss: 1.1575e-04 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 49s 19ms/step - loss: 1.7869e-04 - accuracy: 0.9999 - val_loss: 1.1575e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 5.7721e-06 - accuracy: 1.0000Epoch 25/500\n",
      "2633/2633 [==============================] - 46s 18ms/step - loss: 1.4448e-04 - accuracy: 1.0000 - val_loss: 1.0659e-04 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 46s 18ms/step - loss: 1.4448e-04 - accuracy: 1.0000 - val_loss: 1.0659e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "   1/2633 [..............................] - ETA: 21s - loss: 7.9853e-04 - accuracy: 1.0000Epoch 26/500\n",
      "2633/2633 [==============================] - 51s 19ms/step - loss: 1.4407e-04 - accuracy: 1.0000 - val_loss: 8.7134e-05 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 51s 19ms/step - loss: 1.4407e-04 - accuracy: 1.0000 - val_loss: 8.7134e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "  47/2633 [..............................] - ETA: 1:12 - loss: 3.9537e-04 - accuracy: 0.9999Epoch 27/500\n",
      "2633/2633 [==============================] - 43s 16ms/step - loss: 1.4721e-04 - accuracy: 1.0000 - val_loss: 8.2545e-05 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 43s 16ms/step - loss: 1.4721e-04 - accuracy: 1.0000 - val_loss: 8.2545e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "   1/2633 [..............................] - ETA: 42s - loss: 1.1993e-04 - accuracy: 1.0000Epoch 28/500\n",
      "2633/2633 [==============================] - 50s 19ms/step - loss: 1.4199e-04 - accuracy: 1.0000 - val_loss: 7.3580e-05 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 50s 19ms/step - loss: 1.4199e-04 - accuracy: 1.0000 - val_loss: 7.3580e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "   1/2633 [..............................] - ETA: 13s - loss: 3.1972e-04 - accuracy: 1.0000Epoch 29/500\n",
      "2633/2633 [==============================] - 45s 17ms/step - loss: 1.4093e-04 - accuracy: 1.0000 - val_loss: 6.7915e-05 - val_accuracy: 1.0000 loss: 1.4143e-04 \n",
      "Epoch 30/500\n",
      "2633/2633 [==============================] - 45s 17ms/step - loss: 1.4093e-04 - accuracy: 1.0000 - val_loss: 6.7915e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "2633/2633 [==============================] - 44s 17ms/step - loss: 1.2637e-04 - accuracy: 1.0000 - val_loss: 8.7949e-05 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 44s 17ms/step - loss: 1.2637e-04 - accuracy: 1.0000 - val_loss: 8.7949e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 3.7690e-05 - accuracy: 1.0000Epoch 31/500\n",
      "2633/2633 [==============================] - 46s 18ms/step - loss: 1.4115e-04 - accuracy: 1.0000 - val_loss: 6.7782e-05 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 46s 18ms/step - loss: 1.4115e-04 - accuracy: 1.0000 - val_loss: 6.7782e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "   1/2633 [..............................] - ETA: 38s - loss: 2.0034e-05 - accuracy: 1.0000Epoch 32/500\n",
      "2633/2633 [==============================] - 47s 18ms/step - loss: 1.2510e-04 - accuracy: 1.0000 - val_loss: 8.0797e-05 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 47s 18ms/step - loss: 1.2510e-04 - accuracy: 1.0000 - val_loss: 8.0797e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "   1/2633 [..............................] - ETA: 38s - loss: 1.0816e-05 - accuracy: 1.0000Epoch 33/500\n",
      "2633/2633 [==============================] - 45s 17ms/step - loss: 1.1314e-04 - accuracy: 1.0000 - val_loss: 6.8295e-05 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 45s 17ms/step - loss: 1.1314e-04 - accuracy: 1.0000 - val_loss: 6.8295e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 2.6832e-06 - accuracy: 1.0000Epoch 34/500\n",
      "2633/2633 [==============================] - 46s 18ms/step - loss: 1.2198e-04 - accuracy: 1.0000 - val_loss: 7.1679e-05 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 46s 18ms/step - loss: 1.2198e-04 - accuracy: 1.0000 - val_loss: 7.1679e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "   1/2633 [..............................] - ETA: 34s - loss: 1.4270e-05 - accuracy: 1.0000Epoch 35/500\n",
      "2633/2633 [==============================] - 54s 21ms/step - loss: 1.0009e-04 - accuracy: 1.0000 - val_loss: 6.7712e-05 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 54s 21ms/step - loss: 1.0009e-04 - accuracy: 1.0000 - val_loss: 6.7712e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "   1/2633 [..............................] - ETA: 54s - loss: 1.3830e-06 - accuracy: 1.0000Epoch 36/500\n",
      "2633/2633 [==============================] - 49s 19ms/step - loss: 1.0225e-04 - accuracy: 1.0000 - val_loss: 5.2888e-05 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 49s 19ms/step - loss: 1.0225e-04 - accuracy: 1.0000 - val_loss: 5.2888e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 3.6184e-06 - accuracy: 1.0000Epoch 37/500\n",
      "2633/2633 [==============================] - 46s 18ms/step - loss: 1.1339e-04 - accuracy: 1.0000 - val_loss: 3.9901e-05 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 46s 18ms/step - loss: 1.1339e-04 - accuracy: 1.0000 - val_loss: 3.9901e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "   1/2633 [..............................] - ETA: 57s - loss: 1.1722e-05 - accuracy: 1.0000Epoch 38/500\n",
      "2633/2633 [==============================] - 47s 18ms/step - loss: 9.9501e-05 - accuracy: 1.0000 - val_loss: 8.8694e-05 - val_accuracy: 1.00000s - loss: 9.9540e\n",
      "2633/2633 [==============================] - 47s 18ms/step - loss: 9.9501e-05 - accuracy: 1.0000 - val_loss: 8.8694e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "   1/2633 [..............................] - ETA: 32s - loss: 1.9255e-06 - accuracy: 1.0000Epoch 39/500\n",
      "2633/2633 [==============================] - 47s 18ms/step - loss: 1.0558e-04 - accuracy: 1.0000 - val_loss: 5.0170e-05 - val_accuracy: 1.0000 - los - ETA: 0s - loss: 1.0376e-04 - accuracy: 1.0000 - ETA: 0s - loss: 1.0376e-04 - ac\n",
      "2633/2633 [==============================] - 47s 18ms/step - loss: 1.0558e-04 - accuracy: 1.0000 - val_loss: 5.0170e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 6.0487e-06 - accuracy: 1.0000Epoch 40/500\n",
      "2633/2633 [==============================] - 48s 18ms/step - loss: 1.1331e-04 - accuracy: 1.0000 - val_loss: 5.1971e-05 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 48s 18ms/step - loss: 1.1331e-04 - accuracy: 1.0000 - val_loss: 5.1971e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 1.7525e-05 - accuracy: 1.0000Epoch 41/500\n",
      "2633/2633 [==============================] - 45s 17ms/step - loss: 7.0291e-05 - accuracy: 1.0000 - val_loss: 6.8541e-05 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 45s 17ms/step - loss: 7.0291e-05 - accuracy: 1.0000 - val_loss: 6.8541e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "   1/2633 [..............................] - ETA: 50s - loss: 2.9639e-07 - accuracy: 1.0000Epoch 42/500\n",
      "2633/2633 [==============================] - 45s 17ms/step - loss: 1.1084e-04 - accuracy: 1.0000 - val_loss: 5.0343e-05 - val_accuracy: 1.0000 - loss: 1.1235e-04 - accuracy: 1.02515/2633 [===========================>..] - ETA: 1s - loss: 1.\n",
      "2633/2633 [==============================] - 45s 17ms/step - loss: 1.1084e-04 - accuracy: 1.0000 - val_loss: 5.0343e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 5.2398e-04 - accuracy: 1.0000Epoch 43/500\n",
      "2633/2633 [==============================] - 59s 22ms/step - loss: 8.6872e-05 - accuracy: 1.0000 - val_loss: 5.8646e-05 - val_accuracy: 1.0000\n",
      "2633/2633 [==============================] - 59s 22ms/step - loss: 8.6872e-05 - accuracy: 1.0000 - val_loss: 5.8646e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "   1/2633 [..............................] - ETA: 41s - loss: 7.4699e-06 - accuracy: 1.0000Epoch 44/500\n",
      "2633/2633 [==============================] - 56s 21ms/step - loss: 8.4906e-05 - accuracy: 1.0000 - val_loss: 5.0800e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "2633/2633 [==============================] - 56s 21ms/step - loss: 8.4906e-05 - accuracy: 1.0000 - val_loss: 5.0800e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "2633/2633 [==============================] - 58s 22ms/step - loss: 1.0774e-04 - accuracy: 1.0000 - val_loss: 4.8751e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "2633/2633 [==============================] - 58s 22ms/step - loss: 1.0774e-04 - accuracy: 1.0000 - val_loss: 4.8751e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "2633/2633 [==============================] - 59s 22ms/step - loss: 7.7352e-05 - accuracy: 1.0000 - val_loss: 5.0697e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "2633/2633 [==============================] - 59s 22ms/step - loss: 7.7352e-05 - accuracy: 1.0000 - val_loss: 5.0697e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "2633/2633 [==============================] - 68s 26ms/step - loss: 8.7152e-05 - accuracy: 1.0000 - val_loss: 4.7523e-05 - val_accuracy: 1.00005s - loss: 1.086 - ETA: 50s - loss: 1.2185e - ETA: 49s - loss: 1.1003 - ETA: 24s - loss: 1.1895e-04 - a1553/2633 [================>.............] - ETA: 23s - loss: 1.1878e-04 - accu - ETA: 23s  384/2633 [===>..........................] - ETA: 47s - loss: 1.1087e-04 - accuracy: 1.0 - ETA: 46s - loss: 1.1004e-04 - accurac1785/2633 [===================>..........] - ETA: 18s - loss: 1.0745e-04 - accura 557/2633 [=====>........................] - ETA: 43s   - ETA: 39s - loss: 1.2211e-04 - accuracy: 1.00 - ETA: 15s - loss: 1.0469e-04 - accuracy: 1.0 - ETA: 15s -  - ETA: 35s - loss: 1.2467e-04 - accuracy: 1.0001117/2633 [===========>.......1341/2633 [==============>...............] - ETA: \n",
      "1389/2633 [==============>...............] - ETA: 26s - loss: 1.1249e-04 - accuracy: 1.0000Epoch 48/500\n",
      "2633/2633 [==============================] - 68s 26ms/step - loss: 8.7152e-05 - accuracy: 1.0000 - val_loss: 4.7523e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "2633/2633 [==============================] - 69s 26ms/step - loss: 9.4233e-05 - accuracy: 1.0000 - val_loss: 6.5913e-05 - val_accuracy: 1.0000\n",
      "2197/2633 [========================>.....] - ETA: 10s - loss: 1.0453e-04 - accuracy: 1.0000Epoch 49/500\n",
      "2633/2633 [==============================] - 69s 26ms/step - loss: 9.4233e-05 - accuracy: 1.0000 - val_loss: 6.5913e-05 - val_accuracy: 1.0000\n",
      " 412/2633 [===>..........................]Epoch 49/500\n",
      "2633/2633 [==============================] - 68s 26ms/step - loss: 8.4301e-05 - accuracy: 1.0000 - val_loss: 6.9910e-05 - val_accuracy: 1.0000TA: 20s - loss1843/2631126/2633 [===========>..................] - ETA2035/2633 [======================>.......] - ETA: 14s - loss: 7.4758e-05 -1216/2633 [======\n",
      "Epoch 50/500\n",
      "2633/2633 [==============================] - 63s 24ms/step - loss: 8.4505e-05 - accuracy: 1.0000 - val_loss: 6.5109e-05 - val_accuracy: 1.0000\n",
      "1876/2633 [====================>.........] - ETA: 15s - loss: 7.3400e-05 - accuracy: 1.0000Epoch 55/500\n",
      "2633/2633 [==============================] - 62s 24ms/step - loss: 5.4998e-05 - accuracy: 1.0000 - val_loss: 5.4584e-05 - val_accuracy: 1.0000\n",
      "1031/2633 [==========>...................] - ETA: 42s - loss: 7.0649e-05 - accuracy: 1.0000Epoch 56/500\n",
      "2633/2633 [==============================] - 68s 26ms/step - loss: 7.6052e-05 - accuracy: 1.0000 - val_loss: 4.2056e-05 - val_accuracy: 1.0000\n",
      " 621/2633 [======>.......................] - ETA: 43s - loss: 6.8392e-05 - accuracy: 1.0000Epoch 54/500\n",
      "2523/2633 [===========================>..] - ETA: 2s - loss: 5.6473e-05 - accuracy: 1.00000 - ETA: 42s - loss: 9.03 - ETA: 50s - loss: 3.9221e-05 - accuracy:  - ETA: 41s - loss: 8. - ETA: 40s - loss: 8.6 220/2633 [=>...... 5 - EAccuracy: 0.88148, Precision: 0.88148, Recall: 0.88148\n",
      "2633/2633 [==============================] - 62s 24ms/step - loss: 5.4998e-05 - accuracy: 1.0000 - val_loss: 5.4584e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "1463/2633 [===============>..............] - ETA: 25s - loss: 8.1544e-05 - accuracy: 1.0000- ETA: 32 - ETA: 26s - loss: 8.4085e-05 -Accuracy: 0.88148, Precision: 0.88148, Recall: 0.88148\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, LSTM, Dropout, Input\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "num_folds = 5\n",
    "verbosity = 1\n",
    "n_classes = 2\n",
    "n_features = X_train_lstm.shape[2]\n",
    "activation = 'relu'\n",
    "batch_size = 1024\n",
    "dropout_rate = 0.2\n",
    "epochs = 500\n",
    "kernel_initializer = 'normal'\n",
    "lstm_units_1 = 50\n",
    "lstm_units_2 = 30\n",
    "lstm_units_3 = 50\n",
    "optimizer = 'Adamax'\n",
    "\n",
    "\n",
    "callback_early_stopping = EarlyStopping(patience=20, mode='min', restore_best_weights=True)\n",
    "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.001)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=lstm_units_1, activation=activation, kernel_initializer=kernel_initializer, return_sequences=True, input_shape=(timesteps, features)))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(LSTM(units=lstm_units_2, activation=activation, kernel_initializer=kernel_initializer, return_sequences=True))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(LSTM(units=lstm_units_3, activation=activation, kernel_initializer=kernel_initializer))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    " \n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Training...')\n",
    "\n",
    "history = model.fit(X_train_lstm, y_train_pca, validation_split=0.2, \n",
    "                    callbacks=[callback_early_stopping, callback_reduce_lr],\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=no_epochs,\n",
    "                    verbose=verbosity)\n",
    "\n",
    "# DeÄŸerlendirme metriklerini hesapla\n",
    "true_labels = y_test\n",
    "\n",
    "predictions = model.predict(X_test_lstm)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.5f}, Precision: {precision:.5f}, Recall: {recall:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77ea8c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_matrix(y_true, y_pred, labels=None):\n",
    "    mlm = multilabel_confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    df_performance = pd.DataFrame(index=labels, columns=['accuracy', 'precision', 'recall', 'f1_score'])\n",
    "    for i, label in enumerate(labels):\n",
    "        tn, fp, fn, tp = mlm[i].ravel()\n",
    "        accuracy = (tn + tp) / (tn + fp + fn + tp)\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1_score = 2*precision * recall / (precision + recall)\n",
    "        df_performance.loc[label] = [round(accuracy, 4), round(precision,4), \\\n",
    "                                     round(recall, 4), round(f1_score,4)]\n",
    "    return df_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69e19dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import cycle\n",
    "def RoC_Curve(y_score, y_resample, labels, title): \n",
    "    y_cat = to_categorical(y_resample)\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    lw = 2\n",
    "    # First aggregate all false positive rates\n",
    "    n_classes = len(labels)\n",
    "#     print('n_classes:', n_classes)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_cat[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_cat.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.4f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label='macro-average ROC curve (area = {0:0.4f})'\n",
    "                   ''.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(fpr[i], tpr[i], lw=lw,\n",
    "                 label=f'ROC curve of class {labels[i]} (area = {roc_auc[i]:0.4f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f02f851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on training set\n",
    "y_train_pred_prob = model.predict(X_train_lstm)\n",
    "y_test_pred_prob = model.predict(X_test_lstm)\n",
    "y_train_pred = np.argmax(y_train_pred_prob, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_labels = le.inverse_transform(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65156c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207811bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8105f9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n",
      "{0: 0, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import  LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "y_train_pca = le.fit_transform(y_train_pca)\n",
    "\n",
    "y_test_pca = le.transform(y_test_pca)\n",
    "\n",
    "labels_dict = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "print(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4be804b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accuracy precision recall f1_score\n",
       "0        1    0.9999      1   0.9999\n",
       "1        1         1      1        1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accuracy precision recall f1_score\n",
       "0        1    0.9999      1   0.9999\n",
       "1        1         1      1        1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "y_train_pred_labels = le.inverse_transform(y_train_pred)\n",
    "y_train_labels = le.inverse_transform(y_train_pca)\n",
    "\n",
    "performance = multilabel_matrix(y_train_pred_labels, y_train_labels, labels=le.classes_)\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71991d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_labels = le.inverse_transform(y_test_pred)\n",
    "y_test_true_labels = le.inverse_transform(y_test_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"accuracy score:\", metrics.accuracy_score(y_test_true_labels,y_test_pred_labels ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3101797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e4f0443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accuracy precision  recall f1_score\n",
       "0        1    0.9999  0.9999   0.9999\n",
       "1        1         1       1        1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accuracy precision  recall f1_score\n",
       "0        1    0.9999  0.9999   0.9999\n",
       "1        1         1       1        1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = multilabel_matrix(y_test_true_labels, y_test_pred_labels, labels=le.classes_)\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1162a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_true=y_test_pca, y_pred=y_test_pred)\n",
    "#\n",
    "# Print the confusion matrix using Matplotlib\n",
    "#\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Tahmin', fontsize=18)\n",
    "plt.ylabel('GerÃ§ek', fontsize=18)\n",
    "plt.title('KarmaÅŸÄ±klÄ±k Matrisi', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dc11ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
